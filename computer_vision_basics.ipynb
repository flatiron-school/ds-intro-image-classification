{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An overview of how a computer looks at an image, and how to use that for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports!\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import skimage.io as io\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x) # to make it look better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, and example of how a computer breaks an image down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and Display \n",
    "\n",
    "img = io.imread('http://www.colorwiki.com/images/0/0a/Photodisc.png')\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How the computer looks at it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, the shape of the photo\n",
    "\n",
    "print(f'There are {img.shape[0]} pixels in the vertical channel')\n",
    "print(f'There are {img.shape[1]} pixels in the horizontal')\n",
    "print(f'There are {img.shape[2]} channels in the \"z-axis\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into color channels\n",
    "red = img[:, :, 0]\n",
    "green = img[:, :, 1]\n",
    "blue = img[:, :, 2]\n",
    "\n",
    "# Plot\n",
    "fig, axs = plt.subplots(2,2, figsize=(12,12))\n",
    "\n",
    "\n",
    "# Normal Image\n",
    "cax_00 = axs[0,0].imshow(img)\n",
    "axs[0,0].xaxis.set_major_formatter(plt.NullFormatter())  # kill xlabels\n",
    "axs[0,0].yaxis.set_major_formatter(plt.NullFormatter())  # kill ylabels\n",
    "\n",
    "# Red Channel\n",
    "cax_01 = axs[0,1].imshow(red, cmap='Reds')\n",
    "fig.colorbar(cax_01, ax=axs[0,1])\n",
    "axs[0,1].xaxis.set_major_formatter(plt.NullFormatter())\n",
    "axs[0,1].yaxis.set_major_formatter(plt.NullFormatter())\n",
    "\n",
    "\n",
    "# Green Channel\n",
    "cax_10 = axs[1,0].imshow(green, cmap='Greens')\n",
    "fig.colorbar(cax_10, ax=axs[1,0])\n",
    "axs[1,0].xaxis.set_major_formatter(plt.NullFormatter())\n",
    "axs[1,0].yaxis.set_major_formatter(plt.NullFormatter())\n",
    "\n",
    "# Blue Channel\n",
    "cax_11 = axs[1,1].imshow(blue, cmap='Blues')\n",
    "fig.colorbar(cax_11, ax=axs[1,1])\n",
    "axs[1,1].xaxis.set_major_formatter(plt.NullFormatter())\n",
    "axs[1,1].yaxis.set_major_formatter(plt.NullFormatter())\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some basic information about the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of one of the channels\n",
    "\n",
    "red.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of the data\n",
    "\n",
    "red[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A (very) simple filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using linear algebra, we can transform the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red = red *1.2\n",
    "blue = blue *1.4\n",
    "green = green * 1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-assign to the proper channel in the original image\n",
    "\n",
    "img[:, :, 0] = red\n",
    "img[:, :, 1] = green\n",
    "img[:, :, 2] = blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MNIST Dataset\n",
    "\n",
    "[This Wikipedia](https://en.wikipedia.org/wiki/MNIST_database) article covers the dataset in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset alhtough this returns train and test, we will only be using train\n",
    "(trainX, trainy), (testX, testy) = mnist.load_data()\n",
    "\n",
    "# summarize loaded dataset\n",
    "print('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))\n",
    "\n",
    "# plot first few images\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "\n",
    "for i in range(9):\n",
    "\n",
    "    # define subplot\n",
    "    plt.subplot(330 + 1 + i)\n",
    "\n",
    "    # plot raw pixel data\n",
    "    plt.imshow(trainX[i], cmap=plt.get_cmap('gray'))\n",
    "\n",
    "# show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The labels for the data set\n",
    "\n",
    "trainy[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the matrix into a feature vector for logistic regression\n",
    "\n",
    "flat_trainX = np.reshape(trainX, (trainX.shape[0], (trainX.shape[1]**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_trainX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "\n",
    "flat_trainX = flat_trainX / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_trainX[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression?\n",
    "\n",
    "For image recognition? Seriously?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the logistic Regression\n",
    "\n",
    "lr = LogisticRegression(max_iter=10000, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit (train) the model to the training data\n",
    "# Note: this take about 10 minutes on my machine (MacBookPro)\n",
    "\n",
    "lr.fit(flat_trainX, trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How accurate is it?\n",
    "\n",
    "print(f'This model is {lr.score(flat_trainX, trainy):.2%} accurate.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe predictions and actuals\n",
    "\n",
    "df = pd.DataFrame(trainy, columns=['actual'])\n",
    "df['preds'] = lr.predict(flat_trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with the probability predictions for each class, \n",
    "# and then multiply by 100 to create actual percentages\n",
    "\n",
    "prob_col = ['prob'+str(i) for i in range(10)]\n",
    "probs = (pd.DataFrame(lr.predict_proba(flat_trainX), columns=prob_col)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the probabilities to the main dataframe\n",
    "\n",
    "df = pd.concat([df, probs], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample of predictions that were wrong\n",
    "\n",
    "wrong_sample = df[ df.actual != df.preds ].head(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot first samples\n",
    "i=0\n",
    "plt.figure(figsize=(9,9))\n",
    "for index in wrong_sample.index:\n",
    "    \n",
    "    # define subplot\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    \n",
    "    # plot raw pixel data\n",
    "    plt.imshow(trainX[index], cmap=plt.get_cmap('gray'))\n",
    "    \n",
    "    # tight layout with spacing for title\n",
    "    plt.tight_layout(pad=3.0)\n",
    "    \n",
    "    #get the prediction and actual value\n",
    "    pred,actual = df.iloc[int(index)][['preds','actual']]\n",
    "    \n",
    "    #create the title\n",
    "    plt.title(f'{index} Pred:{int(pred)} Actual:{int(actual)}')\n",
    "    \n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "    \n",
    "# show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at probability table\n",
    "\n",
    "wrong_sample[prob_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the mnist code was derived from [this excellent](https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-from-scratch-for-mnist-handwritten-digit-classification/) tutorial using the Tensorflow version of the dataset\n",
    "\n",
    "The rbg separation was example was adapted from [this stackoverflow](https://stackoverflow.com/questions/39885178/how-can-i-see-the-rgb-channels-of-a-given-image-with-python) article"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
